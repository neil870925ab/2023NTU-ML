{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZlU8khsZjZT"
      },
      "source": [
        "# **Week 4: Colab Experiment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3LRo3ehZo2B"
      },
      "source": [
        "# I. Introduction\n",
        "In this exercise, we load the Breast cancer wisconsin dataset for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn2Bcr9sZofG"
      },
      "source": [
        "# II. Methods\n",
        "We train 3 models:\n",
        "1. logistic regression\n",
        "2. support vector machine\n",
        "3. decision tree.\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4dRDQZqqiet"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import zero_one_loss\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArV6oId2qjCh"
      },
      "outputs": [],
      "source": [
        "# Define the dependent and independent variables.\n",
        "data = load_breast_cancer()\n",
        "Y = data.target\n",
        "X = data.data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmME2cIVMw_C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kY6lUBXL0TX"
      },
      "outputs": [],
      "source": [
        "# Create CV folds\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, random_state=0, shuffle=True)\n",
        "kfold_indices = {}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "  kfold_indices[f\"fold_{i}\"] = {'train': train_index, 'test': test_index}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsTfhZNxL0V1"
      },
      "outputs": [],
      "source": [
        "# Train models and apply them to the test set\n",
        "Error_rate = {'logreg': [], 'svm': [], 'decision_tree': []}\n",
        "param_grid_logreg = {\n",
        "  'C': [0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2],\n",
        "  'penalty': [None],\n",
        "  'solver': ['sag', 'saga']\n",
        "}\n",
        "param_grid_svm = {\n",
        "  'C': [0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2],\n",
        "  'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "param_grid_dt = {\n",
        "  'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "  'min_samples_split': [4],\n",
        "  'min_samples_leaf': [2, 3, 4],\n",
        "  'max_depth': [2, 3, 4, 5],\n",
        "  'max_features': [3, 4, 5, 6, 7, 8],\n",
        "}\n",
        "\n",
        "for fold_id in range(num_folds):\n",
        "  X_train = X[kfold_indices[f\"fold_{fold_id}\"]['train']]\n",
        "  Y_train = Y[kfold_indices[f\"fold_{fold_id}\"]['train']]\n",
        "  X_test = X[kfold_indices[f\"fold_{fold_id}\"]['test']]\n",
        "  Y_test = Y[kfold_indices[f\"fold_{fold_id}\"]['test']]\n",
        "\n",
        "  # TODO : use standardScaler to normalize the data and run the models\n",
        "  scaler = StandardScaler().fit(X_train)\n",
        "  X_train = scaler.transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  # GridSearchCV(estimator, param_grid, scoring='accuracy')\n",
        "  grid_search_logreg = GridSearchCV(LogisticRegression(random_state=87), param_grid_logreg, scoring='accuracy')\n",
        "  grid_search_logreg.fit(X_train, Y_train)\n",
        "  grid_search_svm = GridSearchCV(SVC(random_state=87), param_grid_svm, scoring='accuracy')\n",
        "  grid_search_svm.fit(X_train, Y_train)\n",
        "  grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=87), param_grid_dt, scoring='accuracy')\n",
        "  grid_search_dt.fit(X_train, Y_train)\n",
        "\n",
        "  # Logistic regression\n",
        "  best_model_logreg = grid_search_logreg.best_estimator_\n",
        "  Error_rate['logreg'].append(zero_one_loss(\n",
        "      Y_test, best_model_logreg.predict(X_test)))\n",
        "  # best_params_logreg = grid_search_logreg.best_params_\n",
        "  # print(\"Best Hyperparameters for logreg:\", best_params_logreg)\n",
        "\n",
        "  # SVM\n",
        "  best_model_svm = grid_search_svm.best_estimator_\n",
        "  Error_rate['svm'].append(zero_one_loss(\n",
        "      Y_test, best_model_svm.predict(X_test)))\n",
        "  # best_params_svm = grid_search_svm.best_params_\n",
        "  # print(\"Best Hyperparameters for svm:\", best_params_svm)\n",
        "\n",
        "  # Decision tree\n",
        "  best_model_dt = grid_search_dt.best_estimator_\n",
        "  Error_rate['decision_tree'].append(zero_one_loss(\n",
        "      Y_test, best_model_dt.predict(X_test)))\n",
        "  # best_params_dt = grid_search_dt.best_params_\n",
        "  # print(\"Best Hyperparameters for Decision Tree:\", best_params_dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW0uMLYwZ63z"
      },
      "source": [
        "## III. Results\n",
        "\n",
        "Show the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uD1iPyJP25T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5567b7-706b-4b73-a543-3141c12450ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The error rate over 5 folds in CV:\n",
            "Logistic Regression: mean = 0.0246, std = 0.017\n",
            "SVM: mean = 0.0246, std = 0.0129\n",
            "Decision Tree: mean = 0.0527, std = 0.0199\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "print(f\"The error rate over 5 folds in CV:\")\n",
        "print(f\"Logistic Regression: mean = {round(np.mean(Error_rate['logreg']),4)}, std = {round(np.std(Error_rate['logreg']),4)}\")\n",
        "print(f\"SVM: mean = {round(np.mean(Error_rate['svm']),4)}, std = {round(np.std(Error_rate['svm']),4)}\")\n",
        "print(f\"Decision Tree: mean = {round(np.mean(Error_rate['decision_tree']),4)}, std = {round(np.std(Error_rate['decision_tree']),4)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srwwVH9TaBm3"
      },
      "source": [
        "# IV. Conclusion and Discussion\n",
        "As you can see, Logistic Regression has almost the same performance as SVM.\n",
        "\n",
        "However, Decision Tree performs worse than these two classifiers.\n",
        "\n",
        "Because Decision Tree is sensitive to it's hyperparameter, such like the tree\n",
        "depth,\n",
        "\n",
        "minimum samples per leaf, and pruning, it may perform well only on some\n",
        "\n",
        "specific hyperparameter-configurations.\n",
        "\n",
        "Besides, Decision tree only learns linear-relationsip.\n",
        "\n",
        "Hence, when the job has non-linear characteristic, Decision Tree will perform\n",
        "\n",
        "worse than Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzlGgs1Eazao"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}